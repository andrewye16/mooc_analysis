{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "*MOOC Completion Prediction*\n",
    "1. Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id                                   course_id  completion  \\\n0        1  C_course-v1:TsinghuaX+00740043X_2015_T2+sp           0   \n1        1        C_course-v1:TsinghuaX+00740113_1X+sp           0   \n2        1           C_course-v1:TsinghuaX+30240184+sp           0   \n3        1          C_course-v1:TsinghuaX+30240243X+sp           0   \n4        1        C_course-v1:TsinghuaX+00740113_2X+sp           1   \n\n   local_watch  video_duration  watching_count  video_count  \n0         7697          8439.0              34           18  \n1         1618          1612.0              10            3  \n2         1386          1155.0               7            5  \n3         2614          2612.0               7            4  \n4          527          1684.0               5            2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>course_id</th>\n      <th>completion</th>\n      <th>local_watch</th>\n      <th>video_duration</th>\n      <th>watching_count</th>\n      <th>video_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>C_course-v1:TsinghuaX+00740043X_2015_T2+sp</td>\n      <td>0</td>\n      <td>7697</td>\n      <td>8439.0</td>\n      <td>34</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>C_course-v1:TsinghuaX+00740113_1X+sp</td>\n      <td>0</td>\n      <td>1618</td>\n      <td>1612.0</td>\n      <td>10</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>C_course-v1:TsinghuaX+30240184+sp</td>\n      <td>0</td>\n      <td>1386</td>\n      <td>1155.0</td>\n      <td>7</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>C_course-v1:TsinghuaX+30240243X+sp</td>\n      <td>0</td>\n      <td>2614</td>\n      <td>2612.0</td>\n      <td>7</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>C_course-v1:TsinghuaX+00740113_2X+sp</td>\n      <td>1</td>\n      <td>527</td>\n      <td>1684.0</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv(\"MOOC_AGG_1NF.csv\")\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_id    object\n",
      "counts        int64\n",
      "dtype: object\n",
      "user_id             int64\n",
      "course_id          object\n",
      "completion          int64\n",
      "local_watch         int64\n",
      "video_duration    float64\n",
      "watching_count      int64\n",
      "video_count         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# read another dataset\n",
    "df2 = pd.read_csv(\"MOOC_Course_count.csv\")\n",
    "df2['counts'] = df2['counts'].astype(int)\n",
    "\n",
    "# print type for each column\n",
    "print(df2.dtypes)\n",
    "print(df.dtypes)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id                                   course_id  completion  \\\n0        1  C_course-v1:TsinghuaX+00740043X_2015_T2+sp           0   \n1        1        C_course-v1:TsinghuaX+00740113_1X+sp           0   \n2        1           C_course-v1:TsinghuaX+30240184+sp           0   \n3        1          C_course-v1:TsinghuaX+30240243X+sp           0   \n4        1        C_course-v1:TsinghuaX+00740113_2X+sp           1   \n\n   local_watch  video_duration  watching_count  video_count  counts  \n0         7697          8439.0              34           18     115  \n1         1618          1612.0              10            3      36  \n2         1386          1155.0               7            5     235  \n3         2614          2612.0               7            4     137  \n4          527          1684.0               5            2      55  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>course_id</th>\n      <th>completion</th>\n      <th>local_watch</th>\n      <th>video_duration</th>\n      <th>watching_count</th>\n      <th>video_count</th>\n      <th>counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>C_course-v1:TsinghuaX+00740043X_2015_T2+sp</td>\n      <td>0</td>\n      <td>7697</td>\n      <td>8439.0</td>\n      <td>34</td>\n      <td>18</td>\n      <td>115</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>C_course-v1:TsinghuaX+00740113_1X+sp</td>\n      <td>0</td>\n      <td>1618</td>\n      <td>1612.0</td>\n      <td>10</td>\n      <td>3</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>C_course-v1:TsinghuaX+30240184+sp</td>\n      <td>0</td>\n      <td>1386</td>\n      <td>1155.0</td>\n      <td>7</td>\n      <td>5</td>\n      <td>235</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>C_course-v1:TsinghuaX+30240243X+sp</td>\n      <td>0</td>\n      <td>2614</td>\n      <td>2612.0</td>\n      <td>7</td>\n      <td>4</td>\n      <td>137</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>C_course-v1:TsinghuaX+00740113_2X+sp</td>\n      <td>1</td>\n      <td>527</td>\n      <td>1684.0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>55</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join tables to get information\n",
    "df_new = pd.merge(df, df2, how=\"left\", on=\"course_id\")\n",
    "df_new.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id                                   course_id  dropped  local_watch  \\\n0        1  C_course-v1:TsinghuaX+00740043X_2015_T2+sp        0         7697   \n1        1        C_course-v1:TsinghuaX+00740113_1X+sp        0         1618   \n2        1           C_course-v1:TsinghuaX+30240184+sp        0         1386   \n3        1          C_course-v1:TsinghuaX+30240243X+sp        0         2614   \n4        1        C_course-v1:TsinghuaX+00740113_2X+sp        1          527   \n\n   video_total  watching_count  episodes_watched  episodes_percentile  \\\n0       8439.0              34                18             0.156522   \n1       1612.0              10                 3             0.083333   \n2       1155.0               7                 5             0.021277   \n3       2612.0               7                 4             0.029197   \n4       1684.0               5                 2             0.036364   \n\n   watching_speed  \n0        0.912075  \n1        1.003722  \n2        1.200000  \n3        1.000766  \n4        0.312945  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>course_id</th>\n      <th>dropped</th>\n      <th>local_watch</th>\n      <th>video_total</th>\n      <th>watching_count</th>\n      <th>episodes_watched</th>\n      <th>episodes_percentile</th>\n      <th>watching_speed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>C_course-v1:TsinghuaX+00740043X_2015_T2+sp</td>\n      <td>0</td>\n      <td>7697</td>\n      <td>8439.0</td>\n      <td>34</td>\n      <td>18</td>\n      <td>0.156522</td>\n      <td>0.912075</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>C_course-v1:TsinghuaX+00740113_1X+sp</td>\n      <td>0</td>\n      <td>1618</td>\n      <td>1612.0</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0.083333</td>\n      <td>1.003722</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>C_course-v1:TsinghuaX+30240184+sp</td>\n      <td>0</td>\n      <td>1386</td>\n      <td>1155.0</td>\n      <td>7</td>\n      <td>5</td>\n      <td>0.021277</td>\n      <td>1.200000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>C_course-v1:TsinghuaX+30240243X+sp</td>\n      <td>0</td>\n      <td>2614</td>\n      <td>2612.0</td>\n      <td>7</td>\n      <td>4</td>\n      <td>0.029197</td>\n      <td>1.000766</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>C_course-v1:TsinghuaX+00740113_2X+sp</td>\n      <td>1</td>\n      <td>527</td>\n      <td>1684.0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0.036364</td>\n      <td>0.312945</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature engineering\n",
    "\n",
    "df_new.rename(columns={'video_count': 'episodes_watched', 'video_duration': 'video_total', \"completion\" : \"dropped\"}, inplace=True)\n",
    "df_new['episodes_percentile'] = df_new.apply(lambda x: x['episodes_watched'] / x['counts'], axis=1)\n",
    "df_new['watching_speed'] = df_new.apply(lambda x: x['local_watch'] / x['video_total'], axis=1)\n",
    "df_new.drop(['counts'], axis=1, inplace=True)\n",
    "\n",
    "df_new.head()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Create dictionary to convert string to int and enable the model to process the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w5/8p8hjbzs55d977j35rr3ls4w0000gn/T/ipykernel_1021/1855487061.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new['course_id'][i] = dict_1.get(df_new['course_id'][i])\n"
     ]
    },
    {
     "data": {
      "text/plain": "   user_id course_id  dropped  local_watch  video_total  watching_count  \\\n0        1         0        0         7697       8439.0              34   \n1        1         1        0         1618       1612.0              10   \n2        1         2        0         1386       1155.0               7   \n3        1         3        0         2614       2612.0               7   \n4        1         4        1          527       1684.0               5   \n\n   episodes_watched  episodes_percentile  watching_speed  \n0                18             0.156522        0.912075  \n1                 3             0.083333        1.003722  \n2                 5             0.021277        1.200000  \n3                 4             0.029197        1.000766  \n4                 2             0.036364        0.312945  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>course_id</th>\n      <th>dropped</th>\n      <th>local_watch</th>\n      <th>video_total</th>\n      <th>watching_count</th>\n      <th>episodes_watched</th>\n      <th>episodes_percentile</th>\n      <th>watching_speed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7697</td>\n      <td>8439.0</td>\n      <td>34</td>\n      <td>18</td>\n      <td>0.156522</td>\n      <td>0.912075</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1618</td>\n      <td>1612.0</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0.083333</td>\n      <td>1.003722</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1386</td>\n      <td>1155.0</td>\n      <td>7</td>\n      <td>5</td>\n      <td>0.021277</td>\n      <td>1.200000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2614</td>\n      <td>2612.0</td>\n      <td>7</td>\n      <td>4</td>\n      <td>0.029197</td>\n      <td>1.000766</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>527</td>\n      <td>1684.0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0.036364</td>\n      <td>0.312945</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary for string to int conversion\n",
    "dict_1 = {}\n",
    "for i, k in enumerate(df_new['course_id'].unique()):\n",
    "    dict_1[k] = i\n",
    "\n",
    "# apply that dictionary to the dataset\n",
    "\n",
    "for i in range(len(df_new['course_id'])):\n",
    "    df_new['course_id'][i] = dict_1.get(df_new['course_id'][i])\n",
    "\n",
    "\n",
    "\n",
    "df_new.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "        user_id course_id  dropped  local_watch  video_total  watching_count  \\\n1699        318        23        0          569       1946.0              13   \n104452    18989        87        0         9012       7145.0              71   \n15058      2755       111        1         8295       8679.0              63   \n221723    40241        62        0        36345       4706.0              61   \n11168      2040       174        0         1668       1268.0              27   \n\n        episodes_watched  episodes_percentile  watching_speed  \n1699                   4             0.049383        0.292395  \n104452                14             0.125000        1.261302  \n15058                 14             0.093333        0.955755  \n221723                 8             0.095238        7.723119  \n11168                 16             0.216216        1.315457  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>course_id</th>\n      <th>dropped</th>\n      <th>local_watch</th>\n      <th>video_total</th>\n      <th>watching_count</th>\n      <th>episodes_watched</th>\n      <th>episodes_percentile</th>\n      <th>watching_speed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1699</th>\n      <td>318</td>\n      <td>23</td>\n      <td>0</td>\n      <td>569</td>\n      <td>1946.0</td>\n      <td>13</td>\n      <td>4</td>\n      <td>0.049383</td>\n      <td>0.292395</td>\n    </tr>\n    <tr>\n      <th>104452</th>\n      <td>18989</td>\n      <td>87</td>\n      <td>0</td>\n      <td>9012</td>\n      <td>7145.0</td>\n      <td>71</td>\n      <td>14</td>\n      <td>0.125000</td>\n      <td>1.261302</td>\n    </tr>\n    <tr>\n      <th>15058</th>\n      <td>2755</td>\n      <td>111</td>\n      <td>1</td>\n      <td>8295</td>\n      <td>8679.0</td>\n      <td>63</td>\n      <td>14</td>\n      <td>0.093333</td>\n      <td>0.955755</td>\n    </tr>\n    <tr>\n      <th>221723</th>\n      <td>40241</td>\n      <td>62</td>\n      <td>0</td>\n      <td>36345</td>\n      <td>4706.0</td>\n      <td>61</td>\n      <td>8</td>\n      <td>0.095238</td>\n      <td>7.723119</td>\n    </tr>\n    <tr>\n      <th>11168</th>\n      <td>2040</td>\n      <td>174</td>\n      <td>0</td>\n      <td>1668</td>\n      <td>1268.0</td>\n      <td>27</td>\n      <td>16</td>\n      <td>0.216216</td>\n      <td>1.315457</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data, testing_data = train_test_split(df_new, test_size=0.2, random_state=25)\n",
    "testing_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "        local_watch    video_total  watching_count  episodes_watched  \\\ncount  1.823470e+05  182347.000000   182347.000000     182347.000000   \nmean   1.001487e+04    7534.285286       81.357171         14.465025   \nstd    2.593600e+04   10809.203539      209.506931         23.485315   \nmin    0.000000e+00      15.000000        1.000000          1.000000   \n25%    4.800000e+02    1159.000000        6.000000          2.000000   \n50%    2.074000e+03    3022.000000       19.000000          5.000000   \n75%    8.393500e+03    9002.000000       70.000000         16.000000   \nmax    1.659818e+06  156099.000000    11832.000000        271.000000   \n\n       episodes_percentile  watching_speed  \ncount        182347.000000   182347.000000  \nmean              0.156127        1.042955  \nstd               0.196244        3.006726  \nmin               0.001961        0.000000  \n25%               0.026786        0.423180  \n50%               0.071429        0.740958  \n75%               0.195122        1.032295  \nmax               1.600000      426.111111  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>local_watch</th>\n      <th>video_total</th>\n      <th>watching_count</th>\n      <th>episodes_watched</th>\n      <th>episodes_percentile</th>\n      <th>watching_speed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.823470e+05</td>\n      <td>182347.000000</td>\n      <td>182347.000000</td>\n      <td>182347.000000</td>\n      <td>182347.000000</td>\n      <td>182347.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.001487e+04</td>\n      <td>7534.285286</td>\n      <td>81.357171</td>\n      <td>14.465025</td>\n      <td>0.156127</td>\n      <td>1.042955</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.593600e+04</td>\n      <td>10809.203539</td>\n      <td>209.506931</td>\n      <td>23.485315</td>\n      <td>0.196244</td>\n      <td>3.006726</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000e+00</td>\n      <td>15.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.001961</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4.800000e+02</td>\n      <td>1159.000000</td>\n      <td>6.000000</td>\n      <td>2.000000</td>\n      <td>0.026786</td>\n      <td>0.423180</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.074000e+03</td>\n      <td>3022.000000</td>\n      <td>19.000000</td>\n      <td>5.000000</td>\n      <td>0.071429</td>\n      <td>0.740958</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8.393500e+03</td>\n      <td>9002.000000</td>\n      <td>70.000000</td>\n      <td>16.000000</td>\n      <td>0.195122</td>\n      <td>1.032295</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.659818e+06</td>\n      <td>156099.000000</td>\n      <td>11832.000000</td>\n      <td>271.000000</td>\n      <td>1.600000</td>\n      <td>426.111111</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actaul_training_data1 = training_data.drop(['dropped'], axis=1)\n",
    "actaul_training_data = actaul_training_data1.drop(['user_id'], axis=1)\n",
    "actaul_training_data.head()\n",
    "\n",
    "actaul_training_label = training_data['dropped']\n",
    "\n",
    "actaul_training_data.describe()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Testing different models (random forest, adaboost, gradientboost)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(max_depth=10, random_state=445)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, random_state=445)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, random_state=445)</pre></div></div></div></div></div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=445, max_depth=10)\n",
    "rf.fit(actaul_training_data, actaul_training_label)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# cross validation\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cross_val_score\n\u001B[0;32m----> 3\u001B[0m scores \u001B[38;5;241m=\u001B[39m cross_val_score(\u001B[43mrf\u001B[49m, actaul_training_data, actaul_training_label)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCross-validated scores:\u001B[39m\u001B[38;5;124m\"\u001B[39m, scores)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMean:\u001B[39m\u001B[38;5;124m\"\u001B[39m, scores\u001B[38;5;241m.\u001B[39mmean())\n",
      "\u001B[0;31mNameError\u001B[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rf, actaul_training_data, actaul_training_label)\n",
    "print(\"Cross-validated scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "actaul_testing_data1 = testing_data.drop(['dropped'], axis=1)\n",
    "actaul_testing_data = actaul_testing_data1.drop(['user_id'], axis=1)\n",
    "actaul_testing_data.head()\n",
    "\n",
    "actaul_testing_label = testing_data['dropped']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7986487375786957\n",
      "Precision: 0.6781422246317882\n",
      "Recall: 0.5719402530102119\n",
      "F1: 0.6205299929720122\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = rf.predict(actaul_testing_data)\n",
    "\n",
    "#testing scores\n",
    "print(\"Accuracy:\",sklearn.metrics.accuracy_score(actaul_testing_label, y_pred))\n",
    "print(\"Precision:\",sklearn.metrics.precision_score(actaul_testing_label, y_pred))\n",
    "print(\"Recall:\",sklearn.metrics.recall_score(actaul_testing_label, y_pred))\n",
    "print(\"F1:\",sklearn.metrics.f1_score(actaul_testing_label, y_pred))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MLEnv/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7884923333406454\n",
      "Precision: 0.6405265708286222\n",
      "Recall: 0.6044048163389727\n",
      "F1: 0.6219416562107905\n"
     ]
    }
   ],
   "source": [
    "# test AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=10)\n",
    "ada = AdaBoostClassifier(base_estimator=dt, n_estimators=100, random_state=445)\n",
    "ada.fit(actaul_training_data, actaul_training_label)\n",
    "\n",
    "#testing scores\n",
    "y_pred_adp = ada.predict(actaul_testing_data)\n",
    "print(\"Accuracy:\",sklearn.metrics.accuracy_score(actaul_testing_label, y_pred_adp))\n",
    "print(\"Precision:\",sklearn.metrics.precision_score(actaul_testing_label, y_pred_adp))\n",
    "print(\"Recall:\",sklearn.metrics.recall_score(actaul_testing_label, y_pred_adp))\n",
    "print(\"F1:\",sklearn.metrics.f1_score(actaul_testing_label, y_pred_adp))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/MLEnv/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# test GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_estimators': [100, 200, 300, 400, 500], 'max_depth': [5, 10, 15, 20, 25]}\n",
    "gb = GradientBoostingClassifier(random_state=445)\n",
    "grid_search = GridSearchCV(gb, param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(actaul_training_data, actaul_training_label)\n",
    "print(grid_search.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8285037401013446\n",
      "Precision: 0.7207792207792207\n",
      "Recall: 0.6598079561042524\n",
      "F1: 0.6889472427787061\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state=445, n_estimators=300, max_depth=10)\n",
    "gb.fit(actaul_training_data, actaul_training_label)\n",
    "\n",
    "#testing scores\n",
    "y_pred_gb = gb.predict(actaul_testing_data)\n",
    "print(\"Accuracy:\",sklearn.metrics.accuracy_score(actaul_testing_label, y_pred_gb))\n",
    "print(\"Precision:\",sklearn.metrics.precision_score(actaul_testing_label, y_pred_gb))\n",
    "print(\"Recall:\",sklearn.metrics.recall_score(actaul_testing_label, y_pred_gb))\n",
    "print(\"F1:\",sklearn.metrics.f1_score(actaul_testing_label, y_pred_gb))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#attempt XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "actaul_training_data['course_id'] = actaul_training_data['course_id'].astype('int')\n",
    "\n",
    "actaul_training_data.dtypes\n",
    "\n",
    "actaul_testing_data['course_id'] = actaul_testing_data['course_id'].astype('int')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(random_state=445, n_estimators=300, max_depth=10)\n",
    "xgb.fit(actaul_training_data, actaul_training_label)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8260907714918727\n",
      "Precision: 0.7139561707035755\n",
      "Recall: 0.6604176192653559\n",
      "F1: 0.6861441013460016\n"
     ]
    }
   ],
   "source": [
    "# testing scores\n",
    "y_pred_xgb = xgb.predict(actaul_testing_data)\n",
    "print(\"Accuracy:\",sklearn.metrics.accuracy_score(actaul_testing_label, y_pred_xgb))\n",
    "print(\"Precision:\",sklearn.metrics.precision_score(actaul_testing_label, y_pred_xgb))\n",
    "print(\"Recall:\",sklearn.metrics.recall_score(actaul_testing_label, y_pred_xgb))\n",
    "print(\"F1:\",sklearn.metrics.f1_score(actaul_testing_label, y_pred_xgb))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Unsupservised Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Experimental support for categorical data is not implemented for current tree method yet.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[63], line 9\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# actaul_training_data_XG = actaul_training_data\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# \u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# actaul_training_data_XG['course_id'].astype(\"category\")\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# print(type(actaul_training_data_XG['course_id']))\u001B[39;00m\n\u001B[1;32m      8\u001B[0m xgb \u001B[38;5;241m=\u001B[39m XGBClassifier(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m25\u001B[39m, max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, enable_categorical\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 9\u001B[0m \u001B[43mxgb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactaul_training_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactaul_training_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m#testing scores\u001B[39;00m\n\u001B[1;32m     12\u001B[0m y_pred_xgb \u001B[38;5;241m=\u001B[39m xgb\u001B[38;5;241m.\u001B[39mpredict(actaul_testing_data)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MLEnv/lib/python3.10/site-packages/xgboost/core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MLEnv/lib/python3.10/site-packages/xgboost/sklearn.py:1468\u001B[0m, in \u001B[0;36mXGBClassifier.fit\u001B[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[1;32m   1459\u001B[0m         params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobjective\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulti:softprob\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1460\u001B[0m     params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_class\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_\n\u001B[1;32m   1462\u001B[0m (\n\u001B[1;32m   1463\u001B[0m     model,\n\u001B[1;32m   1464\u001B[0m     metric,\n\u001B[1;32m   1465\u001B[0m     params,\n\u001B[1;32m   1466\u001B[0m     early_stopping_rounds,\n\u001B[1;32m   1467\u001B[0m     callbacks,\n\u001B[0;32m-> 1468\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_configure_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1469\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_metric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\n\u001B[1;32m   1470\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1471\u001B[0m train_dmatrix, evals \u001B[38;5;241m=\u001B[39m _wrap_evaluation_matrices(\n\u001B[1;32m   1472\u001B[0m     missing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmissing,\n\u001B[1;32m   1473\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1487\u001B[0m     feature_types\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_types,\n\u001B[1;32m   1488\u001B[0m )\n\u001B[1;32m   1490\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m train(\n\u001B[1;32m   1491\u001B[0m     params,\n\u001B[1;32m   1492\u001B[0m     train_dmatrix,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1501\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39mcallbacks,\n\u001B[1;32m   1502\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MLEnv/lib/python3.10/site-packages/xgboost/sklearn.py:892\u001B[0m, in \u001B[0;36mXGBModel._configure_fit\u001B[0;34m(self, booster, eval_metric, params, early_stopping_rounds, callbacks)\u001B[0m\n\u001B[1;32m    890\u001B[0m cat_support \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpu_hist\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapprox\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhist\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m    891\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menable_categorical \u001B[38;5;129;01mand\u001B[39;00m tree_method \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m cat_support:\n\u001B[0;32m--> 892\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    893\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExperimental support for categorical data is not implemented for\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    894\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m current tree method yet.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    895\u001B[0m     )\n\u001B[1;32m    897\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model, metric, params, early_stopping_rounds, callbacks\n",
      "\u001B[0;31mValueError\u001B[0m: Experimental support for categorical data is not implemented for current tree method yet."
     ]
    }
   ],
   "source": [
    "# K-Means Clustering\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
